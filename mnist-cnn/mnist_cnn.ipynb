{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3fc04850",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c29ddb",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "aa09161e",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 10\n",
    "LOSS = 'categorical_crossentropy'\n",
    "OPTIMIZER = 'adam'\n",
    "TEST_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c212e745",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dd8706d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(x_train_raw, y_train_raw),(x_test_raw, y_test_raw) = keras.datasets.mnist.load_data()\n",
    "\n",
    "img_count_train = x_train_raw.shape[0]\n",
    "img_count_test = x_test_raw.shape[0]\n",
    "img_x_dim = x_train_raw.shape[1]\n",
    "img_y_dim = x_train_raw.shape[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40835955",
   "metadata": {},
   "source": [
    "### Confirm handwritten image vs truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e41eae7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handwritten sample #14292 is a '6'\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = random.randrange(img_count_train)\n",
    "print(f\"Handwritten sample #{i} is a '{y_train_raw[i]}'\")\n",
    "plt.imshow(x_train_raw[i], cmap='gray_r', vmin = 0, vmax = 255);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330c988f",
   "metadata": {},
   "source": [
    "## Pre-process Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8b0d0d",
   "metadata": {},
   "source": [
    "The raw input data is N X\\*Y-sized images in the form of [N, X, Y]. So need to reshape input data to N X\\*Y-shaped rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ba522f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train_raw, (img_count_train, img_x_dim * img_y_dim))\n",
    "x_test = np.reshape(x_test_raw, (img_count_test, img_x_dim * img_y_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed267064",
   "metadata": {},
   "source": [
    "One-hot encode the raw labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "524a364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train_raw, NUM_CLASSES)\n",
    "y_test = to_categorical(y_test_raw, NUM_CLASSES)\n",
    "\n",
    "# print(y_train_raw[i:i+5])\n",
    "# print('  -------------------')\n",
    "# print(f\"#{[0,1,2,3,4,5,6,7,8,9]}\")\n",
    "# print(y_train[i:i+5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a26d995",
   "metadata": {},
   "source": [
    "## Build & Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e943cb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_nn(X, y, epochs, batch_size, model_layout):\n",
    "\n",
    "    depth = len(model_layout)\n",
    "    layout_str = '-'.join(str(int(width)) for width in model_layout)\n",
    "    model_name = f\"dense_{epochs}-epochs_{batch_size}-batches_{layout_str}-dense\"\n",
    "    print(f\" -- Building Model: {model_name}\")\n",
    "\n",
    "    # create train & val sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=TEST_SPLIT, shuffle=True)\n",
    "    \n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # first dense layer\n",
    "    model.add(Dense(model_layout[0], input_dim=img_x_dim * img_y_dim, activation='relu'))\n",
    "\n",
    "    # remaining dense layers\n",
    "    for width in model_layout[1:]:\n",
    "        model.add(Dense(width, activation='relu'))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "    # compile the model\n",
    "    tensorboard = TensorBoard(log_dir=f\"logs/{model_name}\")\n",
    "    model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "\n",
    "    # stop fitting early if validation loss gets worse\n",
    "    early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "\n",
    "    # train (fit) the model to the dataset\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        verbose=1,\n",
    "                        callbacks=[early_stop, tensorboard])\n",
    "\n",
    "    # # plot loss during training\n",
    "    # plt.title('Loss')\n",
    "    # plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    # plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    # plt.plot(history.history['loss'], label='loss')\n",
    "    # plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    # plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f54a2ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- Building Model: dense_5-epochs_64-batches_784-196-49-dense\n",
      "(60000, 784)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/mike/dev/aiml-pod/mnist-cnn/mnist_cnn.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/mike/dev/aiml-pod/mnist-cnn/mnist_cnn.ipynb#X16sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m my_model \u001b[39m=\u001b[39m dense_nn(x_train, y_train, \u001b[39m5\u001b[39;49m, \u001b[39m64\u001b[39;49m, [\u001b[39m784\u001b[39;49m, \u001b[39m784\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m4\u001b[39;49m, \u001b[39m784\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m16\u001b[39;49m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mike/dev/aiml-pod/mnist-cnn/mnist_cnn.ipynb#X16sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m my_model \u001b[39m=\u001b[39m dense_nn(x_train, y_train, \u001b[39m5\u001b[39m, \u001b[39m64\u001b[39m, [\u001b[39m784\u001b[39m\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m, \u001b[39m784\u001b[39m\u001b[39m/\u001b[39m\u001b[39m8\u001b[39m, \u001b[39m784\u001b[39m\u001b[39m/\u001b[39m\u001b[39m16\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mike/dev/aiml-pod/mnist-cnn/mnist_cnn.ipynb#X16sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m my_model \u001b[39m=\u001b[39m dense_nn(x_train, y_train, \u001b[39m5\u001b[39m, \u001b[39m128\u001b[39m, [\u001b[39m784\u001b[39m, \u001b[39m784\u001b[39m\u001b[39m/\u001b[39m\u001b[39m4\u001b[39m, \u001b[39m784\u001b[39m\u001b[39m/\u001b[39m\u001b[39m16\u001b[39m])\n",
      "\u001b[1;32m/Users/mike/dev/aiml-pod/mnist-cnn/mnist_cnn.ipynb Cell 15\u001b[0m in \u001b[0;36mdense_nn\u001b[0;34m(X, y, epochs, batch_size, model_layout)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mike/dev/aiml-pod/mnist-cnn/mnist_cnn.ipynb#X16sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mprint\u001b[39m(X\u001b[39m.\u001b[39mshape)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/mike/dev/aiml-pod/mnist-cnn/mnist_cnn.ipynb#X16sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m img_x_dim \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/mike/dev/aiml-pod/mnist-cnn/mnist_cnn.ipynb#X16sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m img_y_dim \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39;49mshape[\u001b[39m2\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mike/dev/aiml-pod/mnist-cnn/mnist_cnn.ipynb#X16sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m depth \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(model_layout)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/mike/dev/aiml-pod/mnist-cnn/mnist_cnn.ipynb#X16sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# create train & val sets\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "my_model = dense_nn(x_train, y_train, 5, 64, [784, 784/4, 784/16])\n",
    "my_model = dense_nn(x_train, y_train, 5, 64, [784/2, 784/8, 784/16])\n",
    "my_model = dense_nn(x_train, y_train, 5, 128, [784, 784/4, 784/16])\n",
    "my_model = dense_nn(x_train, y_train, 5, 128, [784/2, 784/8, 784/16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ed851a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_nn(X, y, epochs, batch_size, model_layout):\n",
    "\n",
    "    layout_str = '-'.join(str(int(width)) for width in model_layout)\n",
    "    model_name = f\"dense_{epochs}-epochs_{batch_size}-batches_{layout_str}-dense\"\n",
    "    print(f\" -- Building Model: {model_name}\")\n",
    "\n",
    "    img_x_dim = X.shape[1]\n",
    "    img_y_dim = X.shape[2]\n",
    "    depth = len(model_layout)\n",
    "    \n",
    "    # create train & val sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=TEST_SPLIT, shuffle=True)\n",
    "    \n",
    "    # define model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # first dense layer\n",
    "    model.add(Dense(model_layout[0], input_dim=img_x_dim * img_y_dim, activation='relu'))\n",
    "\n",
    "    # remaining dense layers\n",
    "    for width in model_layout[1:]:\n",
    "        model.add(Dense(width, activation='relu'))\n",
    "\n",
    "    # output layer\n",
    "    model.add(Dense(NUM_CLASSES, activation='softmax'))\n",
    "\n",
    "    # compile the model\n",
    "    tensorboard = TensorBoard(log_dir=f\"logs/{model_name}\")\n",
    "    model.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=['accuracy'])\n",
    "\n",
    "    # stop fitting early if validation loss gets worse\n",
    "    early_stop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=3)\n",
    "\n",
    "    # train (fit) the model to the dataset\n",
    "    history = model.fit(X_train, y_train,\n",
    "                        validation_data=(X_val, y_val),\n",
    "                        epochs=epochs,\n",
    "                        batch_size=batch_size,\n",
    "                        verbose=1,\n",
    "                        callbacks=[early_stop, tensorboard])\n",
    "\n",
    "    # plot loss during training\n",
    "    plt.title('Loss')\n",
    "    plt.plot(history.history['accuracy'], label='accuracy')\n",
    "    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    plt.plot(history.history['loss'], label='loss')\n",
    "    plt.plot(history.history['val_loss'], label='val_loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5e4e04",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "470a9bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 56/313 [====>.........................] - ETA: 0s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-07 19:44:08.324206: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step\n",
      "Train MSE:  0.9747\n",
      "Test MSE:  0.9630\n"
     ]
    }
   ],
   "source": [
    "predictions = my_model.predict(x_test)\n",
    "pred_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# evaluate the keras model\n",
    "_, train_mse = my_model.evaluate(x_train, y_train, verbose=0)\n",
    "_, test_mse = my_model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('Train MSE:  %.4f' % train_mse)\n",
    "print('Test MSE:  %.4f' % test_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f05998e",
   "metadata": {},
   "source": [
    "Let's take a look at the wrong predictions. Are they obviously wrong or understandably wrong? (i.e., sloppy handwriting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766c7ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save off the wrong predictions\n",
    "wrong_predictions = x_test_raw[pred_labels != y_test_raw]\n",
    "wrong_labels = pred_labels[pred_labels != y_test_raw]\n",
    "right_labels = y_test_raw[pred_labels != y_test_raw]\n",
    "\n",
    "# Characterize amount of wrongness\n",
    "percent_wrong = wrong_predictions.shape[0]/x_test.shape[0]*100\n",
    "print(f\"Number Wrongly Predicted:  {wrong_predictions.shape[0]}\")\n",
    "print(f\"Percent Wrong Predictions: {percent_wrong:.2f}%\")\n",
    "\n",
    "random_wrong = random.randrange(wrong_predictions.shape[0])\n",
    "print(f\"Handwritten sample #{random_wrong}:\")\n",
    "print(f\" - Predicted: '{wrong_labels[random_wrong]}'\")\n",
    "print(f\" - Actual:     '{right_labels[random_wrong]}'\")\n",
    "plt.imshow(wrong_predictions[random_wrong], cmap='gray_r', vmin = 0, vmax = 255);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93f7780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
